{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e5ee34",
   "metadata": {},
   "source": [
    "## 🔗 Open This Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DavidLangworthy/ds4s/blob/master/Day%205_%20Capstone%20%E2%80%93%20CO%E2%82%82%20Emissions%20%26%20Global%20Temperature.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e56488",
   "metadata": {},
   "source": [
    "# 🔥 Day 5 – Capstone Project: CO₂ and Climate\n",
    "### Telling the Big Story with Data\n",
    "\n",
    "The capstone weaves together data cleaning, diagnostics, multi-source merging, and a polished narrative. You’ll build a two-panel story that shows how human-caused CO₂ emissions track with global temperature change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb41fe8",
   "metadata": {},
   "source": [
    "### 🗂️ Data Card\n",
    "| Field | Details |\n",
    "| --- | --- |\n",
    "| **Dataset** | Global Fossil CO₂ Emissions & NASA GISTEMP |\n",
    "| **Source & link** | Our World in Data (Global Carbon Project) & NASA GISTEMP v4 |\n",
    "| **Temporal / spatial coverage** | Global totals, annual 1880–2023 |\n",
    "| **Key units** | CO₂: gigatonnes per year • Temperature: anomaly in °C (1951–1980 baseline) |\n",
    "| **Method & caveats** | CO₂ data aggregates fossil fuels and cement. Temperature anomalies follow NASA’s 1951–1980 baseline; latest year provisional. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47dee2d",
   "metadata": {},
   "source": [
    "### ⏱️ Learning Path for Today\n",
    "\n",
    "            Each loop takes about 10–15 minutes:\n",
    "            - [ ] Load and validate the CO₂ and temperature datasets.\n",
    "- [ ] Align years and run diagnostics on ranges and nulls.\n",
    "- [ ] Engineer summary metrics for evidence statements.\n",
    "- [ ] Compose a two-panel narrative figure with accessibility checks.\n",
    "\n",
    "            > 👩‍🏫 **Teacher tip:** Use these checkpoints for quick formative assessment. Have students raise a colored card after each check cell to signal confidence or questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52815448",
   "metadata": {},
   "source": [
    "> ### 👩‍🏫 Teacher Sidebar\n",
    "> **Suggested timing:** ~60 minutes including peer feedback.\n",
    ">\n",
    "> **Likely misconceptions:** Assuming correlation equals causation; misreading anomalies as absolute temperatures.\n",
    ">\n",
    "> **Fast finisher extension:** Invite students to add emissions per capita or mitigation milestones as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a177fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Mapping, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    import plotly.express as px  # noqa: F401 - imported for student use\n",
    "except ModuleNotFoundError:  # pragma: no cover - Plotly installed in Colab\n",
    "    px = None\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"axes.labelsize\": 13,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.25,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "STORY_KEYS = (\n",
    "    \"title\",\n",
    "    \"subtitle\",\n",
    "    \"claim\",\n",
    "    \"evidence\",\n",
    "    \"visual\",\n",
    "    \"takeaway\",\n",
    "    \"source\",\n",
    "    \"units\",\n",
    "    \"annotation\",\n",
    "    \"alt_text\",\n",
    ")\n",
    "\n",
    "\n",
    "def load_csv(path: Path, *, description: str = \"\", **read_kwargs) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, **read_kwargs)\n",
    "    label = description or path.name\n",
    "    print(\n",
    "        f\"✅ Loaded {label} with shape {df.shape[0]} rows × {df.shape[1]} columns.\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_columns(\n",
    "    df: pd.DataFrame, required: Sequence[str], *, df_name: str = \"DataFrame\"\n",
    ") -> None:\n",
    "    missing = [col for col in required if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{df_name} is missing columns: {missing}\")\n",
    "    print(f\"✅ {df_name} includes required columns: {', '.join(required)}\")\n",
    "\n",
    "\n",
    "def expect_rows_between(\n",
    "    df: pd.DataFrame,\n",
    "    lower: int,\n",
    "    upper: int,\n",
    "    *,\n",
    "    df_name: str = \"DataFrame\",\n",
    ") -> None:\n",
    "    rows = len(df)\n",
    "    if not (lower <= rows <= upper):\n",
    "        raise ValueError(\n",
    "            f\"{df_name} has {rows} rows; expected between {lower} and {upper}.\"\n",
    "        )\n",
    "    print(f\"✅ {df_name} row count {rows} within [{lower}, {upper}].\")\n",
    "\n",
    "\n",
    "def quick_null_check(df: pd.DataFrame, *, df_name: str = \"DataFrame\") -> pd.Series:\n",
    "    nulls = df.isna().sum()\n",
    "    print(f\"{df_name} missing values per column:\\n{nulls}\")\n",
    "    return nulls\n",
    "\n",
    "\n",
    "def quick_preview(\n",
    "    df: pd.DataFrame, *, n: int = 5, df_name: str = \"DataFrame\"\n",
    ") -> pd.DataFrame:\n",
    "    print(f\"🔍 Previewing {df_name} (first {n} rows):\")\n",
    "    return df.head(n)\n",
    "\n",
    "\n",
    "def numeric_sanity_check(\n",
    "    series: pd.Series,\n",
    "    *,\n",
    "    minimum: float | None = None,\n",
    "    maximum: float | None = None,\n",
    "    name: str = \"Series\",\n",
    ") -> None:\n",
    "    if minimum is not None and series.min() < minimum:\n",
    "        raise ValueError(\n",
    "            f\"{name} has values below the expected minimum of {minimum}.\"\n",
    "        )\n",
    "    if maximum is not None and series.max() > maximum:\n",
    "        raise ValueError(\n",
    "            f\"{name} has values above the expected maximum of {maximum}.\"\n",
    "        )\n",
    "    print(\n",
    "        f\"✅ {name} within expected range\"\n",
    "        f\"{f' ≥ {minimum}' if minimum is not None else ''}\"\n",
    "        f\"{f' and ≤ {maximum}' if maximum is not None else ''}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def story_fields_are_complete(story: Mapping[str, str]) -> None:\n",
    "    missing = [key for key in STORY_KEYS if not str(story.get(key, \"\")).strip()]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Please complete the storytelling scaffold before plotting: \"\n",
    "            + \", \".join(missing)\n",
    "        )\n",
    "    print(\n",
    "        \"✅ Story scaffold complete (title, subtitle, claim, evidence, visual,\"\n",
    "        \" takeaway, source, units, annotation, alt text).\"\n",
    "    )\n",
    "\n",
    "\n",
    "def print_story_scaffold(story: Mapping[str, str]) -> None:\n",
    "    story_fields_are_complete(story)\n",
    "    print(\"\\n📖 Story Scaffold\")\n",
    "    print(f\"Claim: {story['claim']}\")\n",
    "    print(f\"Evidence: {story['evidence']}\")\n",
    "    print(f\"Visual focus: {story['visual']}\")\n",
    "    print(f\"Takeaway: {story['takeaway']}\")\n",
    "    print(f\"Source: {story['source']} ({story['units']})\")\n",
    "\n",
    "\n",
    "def apply_matplotlib_story(ax: plt.Axes, story: Mapping[str, str]) -> None:\n",
    "    story_fields_are_complete(story)\n",
    "    ax.set_title(f\"{story['title']}\\n{story['subtitle']}\", loc=\"left\", pad=18)\n",
    "    ax.figure.text(\n",
    "        0.01,\n",
    "        -0.08,\n",
    "        (\n",
    "            f\"Claim: {story['claim']} | Evidence: {story['evidence']}\"\n",
    "            f\" | Takeaway: {story['takeaway']}\"\n",
    "            f\"\\nSource: {story['source']} • Units: {story['units']}\"\n",
    "        ),\n",
    "        ha=\"left\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "\n",
    "def annotate_callout(\n",
    "    ax: plt.Axes,\n",
    "    *,\n",
    "    xy: tuple[float, float],\n",
    "    xytext: tuple[float, float],\n",
    "    text: str,\n",
    ") -> None:\n",
    "    ax.annotate(\n",
    "        text,\n",
    "        xy=xy,\n",
    "        xytext=xytext,\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1),\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "\n",
    "def record_alt_text(text: str) -> None:\n",
    "    print(f\"📝 Alt text ready: {text}\")\n",
    "\n",
    "\n",
    "def accessibility_checklist(\n",
    "    *, palette: str, has_alt_text: bool, contrast_passed: bool = True\n",
    ") -> None:\n",
    "    print(\"♿ Accessibility checklist:\")\n",
    "    print(f\" • Palette: {palette}\")\n",
    "    print(\n",
    "        f\" • Alt text provided: {'yes' if has_alt_text else 'add alt text before sharing'}\"\n",
    "    )\n",
    "    print(f\" • Contrast OK: {'yes' if contrast_passed else 'adjust colors'}\")\n",
    "\n",
    "\n",
    "def save_figure(fig: plt.Figure, filename: str) -> Path:\n",
    "    plots_dir = Path.cwd() / \"plots\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = plots_dir / filename\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"💾 Saved figure to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def save_plotly_figure(fig, filename: str) -> Path:\n",
    "    plots_dir = Path.cwd() / \"plots\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = plots_dir / filename.replace(\".png\", \".html\")\n",
    "    fig.write_html(html_path)\n",
    "    print(f\"💾 Saved interactive figure to {html_path}\")\n",
    "    try:\n",
    "        static_path = plots_dir / filename\n",
    "        fig.write_image(str(static_path))\n",
    "        print(f\"💾 Saved static image to {static_path}\")\n",
    "    except Exception as exc:  # pragma: no cover - depends on kaleido\n",
    "        print(f\"⚠️ Static export skipped: {exc}\")\n",
    "    return html_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02315e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd() / \"data\"\n",
    "PLOTS_DIR = Path.cwd() / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Plots directory: {PLOTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa20f2b",
   "metadata": {},
   "source": [
    "## Loop 1 · Load & Inspect Both Datasets\n",
    "Keep schemas transparent before merging anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42face57",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_path = DATA_DIR / \"global_co2.csv\"\n",
    "temp_path = DATA_DIR / \"GLB.Ts+dSST.csv\"\n",
    "\n",
    "df_co2 = load_csv(co2_path, description=\"Global fossil CO₂ emissions\")\n",
    "df_temp_raw = load_csv(\n",
    "    temp_path,\n",
    "    description=\"NASA GISTEMP anomalies\",\n",
    "    skiprows=1,\n",
    "    usecols=[\"Year\", \"J-D\"],\n",
    ")\n",
    "\n",
    "validate_columns(df_co2, [\"Year\", \"CO2\"], df_name=\"CO₂ data\")\n",
    "validate_columns(df_temp_raw, [\"Year\", \"J-D\"], df_name=\"temperature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da84e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_preview(df_co2, n=5, df_name=\"CO₂ data\")\n",
    "quick_preview(df_temp_raw, n=5, df_name=\"temperature data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5739fe",
   "metadata": {},
   "source": [
    "## Loop 2 · Clean, Align, and Diagnose\n",
    "Convert to numeric, align year index, and make sure both series overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827488a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2[\"Year\"] = pd.to_numeric(df_co2[\"Year\"], errors=\"coerce\")\n",
    "df_co2[\"CO2\"] = pd.to_numeric(df_co2[\"CO2\"], errors=\"coerce\")\n",
    "\n",
    "df_temp = df_temp_raw.rename(columns={\"J-D\": \"TempAnomaly\"})\n",
    "df_temp[\"TempAnomaly\"] = pd.to_numeric(df_temp[\"TempAnomaly\"], errors=\"coerce\")\n",
    "\n",
    "df_co2 = df_co2.dropna().set_index(\"Year\")\n",
    "df_temp = df_temp.dropna().set_index(\"Year\")\n",
    "\n",
    "df_merged = df_co2.join(df_temp, how=\"inner\")\n",
    "df_merged = df_merged[df_merged.index >= 1880]\n",
    "\n",
    "expect_rows_between(df_merged, 120, 200, df_name=\"merged climate data\")\n",
    "numeric_sanity_check(df_merged[\"CO2\"], minimum=0, maximum=40, name=\"CO₂ (Gt)\")\n",
    "numeric_sanity_check(df_merged[\"TempAnomaly\"], minimum=-1.0, maximum=1.5, name=\"Temperature anomaly (°C)\")\n",
    "quick_null_check(df_merged, df_name=\"merged climate data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_preview(df_merged.head(), n=5, df_name=\"merged climate data\")\n",
    "quick_preview(df_merged.tail(), n=5, df_name=\"recent climate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1579d",
   "metadata": {},
   "source": [
    "## Loop 3 · Engineer Evidence Metrics\n",
    "Quantify change for your claim-evidence statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc45e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_year = 1960\n",
    "start_year = df_merged.index.min()\n",
    "latest_year = int(df_merged.index.max())\n",
    "\n",
    "def safe_value(year: int, series: pd.Series) -> float:\n",
    "    if year in series.index:\n",
    "        return float(series.loc[year])\n",
    "    return float(series.loc[series.index[series.index.searchsorted(year)]])\n",
    "\n",
    "co2_baseline = safe_value(baseline_year, df_merged[\"CO2\"])\n",
    "co2_latest = float(df_merged[\"CO2\"].iloc[-1])\n",
    "temp_baseline = safe_value(baseline_year, df_merged[\"TempAnomaly\"])\n",
    "temp_latest = float(df_merged[\"TempAnomaly\"].iloc[-1])\n",
    "corr = df_merged[\"CO2\"].corr(df_merged[\"TempAnomaly\"])\n",
    "\n",
    "print(\n",
    "    f\"Since {baseline_year}, CO₂ rose from {co2_baseline:.1f} Gt to {co2_latest:.1f} Gt.\"                     f\" Temperature anomaly increased from {temp_baseline:.2f}°C to {temp_latest:.2f}°C.\"\n",
    ")\n",
    "print(f\"Pearson correlation between series: {corr:.2f}\")\n",
    "\n",
    "story = {\n",
    "    \"title\": \"CO₂ Emissions and Global Temperatures Rise in Lockstep\",\n",
    "    \"subtitle\": f\"Global totals, {start_year}–{latest_year}\",\n",
    "    \"claim\": \"Burning fossil fuels drives a steep climb in atmospheric CO₂ and global temperature anomalies.\",\n",
    "    \"evidence\": (\n",
    "        f\"CO₂ emissions quadrupled after {baseline_year}, and temperature anomalies climbed ~{temp_latest - temp_baseline:.1f}°C.\"                         f\" Correlation = {corr:.2f}.\"\n",
    "    ),\n",
    "    \"visual\": \"Two-panel line chart sharing a timeline (top: CO₂, bottom: temperature anomaly).\",\n",
    "    \"takeaway\": \"Cutting emissions is essential to stabilise temperatures within agreed climate targets.\",\n",
    "    \"source\": \"Global Carbon Project & NASA GISTEMP (2024 release)\",\n",
    "    \"units\": \"CO₂ in gigatonnes; temperature anomaly in °C relative to 1951–1980\",\n",
    "    \"annotation\": f\"{latest_year}: {co2_latest:.1f} Gt CO₂ and {temp_latest:.2f}°C anomaly\",\n",
    "    \"alt_text\": (\n",
    "        \"Two aligned line charts from the late 1800s to present showing CO₂ emissions climbing from under 5 Gt\"\n",
    "        f\" to over {co2_latest:.0f} Gt while temperature anomalies rise from near 0°C to about {temp_latest:.1f}°C.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "print_story_scaffold(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e40ae",
   "metadata": {},
   "source": [
    "## Loop 4 · Compose the Capstone Figure\n",
    "Use a shared timeline, consistent storytelling scaffold, and explicit accessibility log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(12, 9),\n",
    "    sharex=True,\n",
    "    gridspec_kw={\"height_ratios\": [2, 1.2], \"hspace\": 0.05},\n",
    ")\n",
    "\n",
    "ax_co2, ax_temp = axes\n",
    "ax_co2.plot(df_merged.index, df_merged[\"CO2\"], color=\"#6a4c93\", linewidth=3)\n",
    "ax_co2.set_ylabel(\"CO₂ emissions (Gt)\")\n",
    "ax_co2.axvspan(1950, latest_year, color=\"#f6bd60\", alpha=0.15, label=\"Great Acceleration\")\n",
    "ax_co2.legend(loc=\"upper left\")\n",
    "\n",
    "ax_temp.plot(df_merged.index, df_merged[\"TempAnomaly\"], color=\"#ef476f\", linewidth=2.5)\n",
    "ax_temp.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax_temp.set_ylabel(\"Temp anomaly (°C)\")\n",
    "ax_temp.set_xlabel(\"Year\")\n",
    "\n",
    "apply_matplotlib_story(ax_co2, story)\n",
    "annotate_callout(\n",
    "    ax_co2,\n",
    "    xy=(latest_year, co2_latest),\n",
    "    xytext=(1985, co2_latest - 10),\n",
    "    text=story[\"annotation\"],\n",
    ")\n",
    "annotate_callout(\n",
    "    ax_temp,\n",
    "    xy=(latest_year, temp_latest),\n",
    "    xytext=(1940, temp_latest + 0.2),\n",
    "    text=f\"{latest_year}: {temp_latest:.2f}°C anomaly\",\n",
    ")\n",
    "\n",
    "record_alt_text(story[\"alt_text\"])\n",
    "accessibility_checklist(\n",
    "    palette=\"Purple/rose contrast with shared timeline\",\n",
    "    has_alt_text=True,\n",
    ")\n",
    "\n",
    "fig.align_ylabels(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cbc1f",
   "metadata": {},
   "source": [
    "### 🧾 Reflection Prompt\n",
    "- Where might the causal chain break? What other evidence would you gather?\n",
    "- How could you adapt this chart for a policymaker vs. a public audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd373b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure(fig, \"day05_solution_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrPwOkZwNEizIssfpEdkJP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
