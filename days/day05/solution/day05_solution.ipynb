{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e5ee34",
   "metadata": {},
   "source": [
    "## ðŸ”— Open This Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DavidLangworthy/ds4s/blob/master/Day%205_%20Capstone%20%E2%80%93%20CO%E2%82%82%20Emissions%20%26%20Global%20Temperature.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e56488",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Day 5 â€“ Capstone Project: COâ‚‚ and Climate\n",
    "### Telling the Big Story with Data\n",
    "\n",
    "The capstone weaves together data cleaning, diagnostics, multi-source merging, and a polished narrative. Youâ€™ll build a two-panel story that shows how human-caused COâ‚‚ emissions track with global temperature change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb41fe8",
   "metadata": {},
   "source": [
    "### ðŸ—‚ï¸ Data Card\n",
    "| Field | Details |\n",
    "| --- | --- |\n",
    "| **Dataset** | Global Fossil COâ‚‚ Emissions & NASA GISTEMP |\n",
    "| **Source & link** | Our World in Data (Global Carbon Project) & NASA GISTEMP v4 |\n",
    "| **Temporal / spatial coverage** | Global totals, annual 1880â€“2023 |\n",
    "| **Key units** | COâ‚‚: gigatonnes per year â€¢ Temperature: anomaly in Â°C (1951â€“1980 baseline) |\n",
    "| **Method & caveats** | COâ‚‚ data aggregates fossil fuels and cement. Temperature anomalies follow NASAâ€™s 1951â€“1980 baseline; latest year provisional. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47dee2d",
   "metadata": {},
   "source": [
    "### â±ï¸ Learning Path for Today\n",
    "\n",
    "            Each loop takes about 10â€“15 minutes:\n",
    "            - [ ] Load and validate the COâ‚‚ and temperature datasets.\n",
    "- [ ] Align years and run diagnostics on ranges and nulls.\n",
    "- [ ] Engineer summary metrics for evidence statements.\n",
    "- [ ] Compose a two-panel narrative figure with accessibility checks.\n",
    "\n",
    "            > ðŸ‘©â€ðŸ« **Teacher tip:** Use these checkpoints for quick formative assessment. Have students raise a colored card after each check cell to signal confidence or questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52815448",
   "metadata": {},
   "source": [
    "> ### ðŸ‘©â€ðŸ« Teacher Sidebar\n",
    "> **Suggested timing:** ~60 minutes including peer feedback.\n",
    ">\n",
    "> **Likely misconceptions:** Assuming correlation equals causation; misreading anomalies as absolute temperatures.\n",
    ">\n",
    "> **Fast finisher extension:** Invite students to add emissions per capita or mitigation milestones as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a177fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Mapping, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    import plotly.express as px  # noqa: F401 - imported for student use\n",
    "except ModuleNotFoundError:  # pragma: no cover - Plotly installed in Colab\n",
    "    px = None\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"axes.labelsize\": 13,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.25,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "STORY_KEYS = (\n",
    "    \"title\",\n",
    "    \"subtitle\",\n",
    "    \"claim\",\n",
    "    \"evidence\",\n",
    "    \"visual\",\n",
    "    \"takeaway\",\n",
    "    \"source\",\n",
    "    \"units\",\n",
    "    \"annotation\",\n",
    "    \"alt_text\",\n",
    ")\n",
    "\n",
    "\n",
    "def load_csv(path: Path, *, description: str = \"\", **read_kwargs) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, **read_kwargs)\n",
    "    label = description or path.name\n",
    "    print(\n",
    "        f\"âœ… Loaded {label} with shape {df.shape[0]} rows Ã— {df.shape[1]} columns.\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_columns(\n",
    "    df: pd.DataFrame, required: Sequence[str], *, df_name: str = \"DataFrame\"\n",
    ") -> None:\n",
    "    missing = [col for col in required if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{df_name} is missing columns: {missing}\")\n",
    "    print(f\"âœ… {df_name} includes required columns: {', '.join(required)}\")\n",
    "\n",
    "\n",
    "def expect_rows_between(\n",
    "    df: pd.DataFrame,\n",
    "    lower: int,\n",
    "    upper: int,\n",
    "    *,\n",
    "    df_name: str = \"DataFrame\",\n",
    ") -> None:\n",
    "    rows = len(df)\n",
    "    if not (lower <= rows <= upper):\n",
    "        raise ValueError(\n",
    "            f\"{df_name} has {rows} rows; expected between {lower} and {upper}.\"\n",
    "        )\n",
    "    print(f\"âœ… {df_name} row count {rows} within [{lower}, {upper}].\")\n",
    "\n",
    "\n",
    "def quick_null_check(df: pd.DataFrame, *, df_name: str = \"DataFrame\") -> pd.Series:\n",
    "    nulls = df.isna().sum()\n",
    "    print(f\"{df_name} missing values per column:\\n{nulls}\")\n",
    "    return nulls\n",
    "\n",
    "\n",
    "def quick_preview(\n",
    "    df: pd.DataFrame, *, n: int = 5, df_name: str = \"DataFrame\"\n",
    ") -> pd.DataFrame:\n",
    "    print(f\"ðŸ” Previewing {df_name} (first {n} rows):\")\n",
    "    return df.head(n)\n",
    "\n",
    "\n",
    "def numeric_sanity_check(\n",
    "    series: pd.Series,\n",
    "    *,\n",
    "    minimum: float | None = None,\n",
    "    maximum: float | None = None,\n",
    "    name: str = \"Series\",\n",
    ") -> None:\n",
    "    if minimum is not None and series.min() < minimum:\n",
    "        raise ValueError(\n",
    "            f\"{name} has values below the expected minimum of {minimum}.\"\n",
    "        )\n",
    "    if maximum is not None and series.max() > maximum:\n",
    "        raise ValueError(\n",
    "            f\"{name} has values above the expected maximum of {maximum}.\"\n",
    "        )\n",
    "    print(\n",
    "        f\"âœ… {name} within expected range\"\n",
    "        f\"{f' â‰¥ {minimum}' if minimum is not None else ''}\"\n",
    "        f\"{f' and â‰¤ {maximum}' if maximum is not None else ''}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def story_fields_are_complete(story: Mapping[str, str]) -> None:\n",
    "    missing = [key for key in STORY_KEYS if not str(story.get(key, \"\")).strip()]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Please complete the storytelling scaffold before plotting: \"\n",
    "            + \", \".join(missing)\n",
    "        )\n",
    "    print(\n",
    "        \"âœ… Story scaffold complete (title, subtitle, claim, evidence, visual,\"\n",
    "        \" takeaway, source, units, annotation, alt text).\"\n",
    "    )\n",
    "\n",
    "\n",
    "def print_story_scaffold(story: Mapping[str, str]) -> None:\n",
    "    story_fields_are_complete(story)\n",
    "    print(\"\\nðŸ“– Story Scaffold\")\n",
    "    print(f\"Claim: {story['claim']}\")\n",
    "    print(f\"Evidence: {story['evidence']}\")\n",
    "    print(f\"Visual focus: {story['visual']}\")\n",
    "    print(f\"Takeaway: {story['takeaway']}\")\n",
    "    print(f\"Source: {story['source']} ({story['units']})\")\n",
    "\n",
    "\n",
    "def apply_matplotlib_story(ax: plt.Axes, story: Mapping[str, str]) -> None:\n",
    "    story_fields_are_complete(story)\n",
    "    ax.set_title(f\"{story['title']}\\n{story['subtitle']}\", loc=\"left\", pad=18)\n",
    "    ax.figure.text(\n",
    "        0.01,\n",
    "        -0.08,\n",
    "        (\n",
    "            f\"Claim: {story['claim']} | Evidence: {story['evidence']}\"\n",
    "            f\" | Takeaway: {story['takeaway']}\"\n",
    "            f\"\\nSource: {story['source']} â€¢ Units: {story['units']}\"\n",
    "        ),\n",
    "        ha=\"left\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "\n",
    "def annotate_callout(\n",
    "    ax: plt.Axes,\n",
    "    *,\n",
    "    xy: tuple[float, float],\n",
    "    xytext: tuple[float, float],\n",
    "    text: str,\n",
    ") -> None:\n",
    "    ax.annotate(\n",
    "        text,\n",
    "        xy=xy,\n",
    "        xytext=xytext,\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1),\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "\n",
    "def record_alt_text(text: str) -> None:\n",
    "    print(f\"ðŸ“ Alt text ready: {text}\")\n",
    "\n",
    "\n",
    "def accessibility_checklist(\n",
    "    *, palette: str, has_alt_text: bool, contrast_passed: bool = True\n",
    ") -> None:\n",
    "    print(\"â™¿ Accessibility checklist:\")\n",
    "    print(f\" â€¢ Palette: {palette}\")\n",
    "    print(\n",
    "        f\" â€¢ Alt text provided: {'yes' if has_alt_text else 'add alt text before sharing'}\"\n",
    "    )\n",
    "    print(f\" â€¢ Contrast OK: {'yes' if contrast_passed else 'adjust colors'}\")\n",
    "\n",
    "\n",
    "def save_figure(fig: plt.Figure, filename: str) -> Path:\n",
    "    plots_dir = Path.cwd() / \"plots\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = plots_dir / filename\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"ðŸ’¾ Saved figure to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def save_plotly_figure(fig, filename: str) -> Path:\n",
    "    plots_dir = Path.cwd() / \"plots\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = plots_dir / filename.replace(\".png\", \".html\")\n",
    "    fig.write_html(html_path)\n",
    "    print(f\"ðŸ’¾ Saved interactive figure to {html_path}\")\n",
    "    try:\n",
    "        static_path = plots_dir / filename\n",
    "        fig.write_image(str(static_path))\n",
    "        print(f\"ðŸ’¾ Saved static image to {static_path}\")\n",
    "    except Exception as exc:  # pragma: no cover - depends on kaleido\n",
    "        print(f\"âš ï¸ Static export skipped: {exc}\")\n",
    "    return html_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02315e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd() / \"data\"\n",
    "PLOTS_DIR = Path.cwd() / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Plots directory: {PLOTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa20f2b",
   "metadata": {},
   "source": [
    "## Loop 1 Â· Load & Inspect Both Datasets\n",
    "Keep schemas transparent before merging anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42face57",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_path = DATA_DIR / \"global_co2.csv\"\n",
    "temp_path = DATA_DIR / \"GLB.Ts+dSST.csv\"\n",
    "\n",
    "df_co2 = load_csv(co2_path, description=\"Global fossil COâ‚‚ emissions\")\n",
    "df_temp_raw = load_csv(\n",
    "    temp_path,\n",
    "    description=\"NASA GISTEMP anomalies\",\n",
    "    skiprows=1,\n",
    "    usecols=[\"Year\", \"J-D\"],\n",
    ")\n",
    "\n",
    "validate_columns(df_co2, [\"Year\", \"CO2\"], df_name=\"COâ‚‚ data\")\n",
    "validate_columns(df_temp_raw, [\"Year\", \"J-D\"], df_name=\"temperature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da84e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_preview(df_co2, n=5, df_name=\"COâ‚‚ data\")\n",
    "quick_preview(df_temp_raw, n=5, df_name=\"temperature data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5739fe",
   "metadata": {},
   "source": [
    "## Loop 2 Â· Clean, Align, and Diagnose\n",
    "Convert to numeric, align year index, and make sure both series overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827488a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2[\"Year\"] = pd.to_numeric(df_co2[\"Year\"], errors=\"coerce\")\n",
    "df_co2[\"CO2\"] = pd.to_numeric(df_co2[\"CO2\"], errors=\"coerce\")\n",
    "\n",
    "df_temp = df_temp_raw.rename(columns={\"J-D\": \"TempAnomaly\"})\n",
    "df_temp[\"TempAnomaly\"] = pd.to_numeric(df_temp[\"TempAnomaly\"], errors=\"coerce\")\n",
    "\n",
    "df_co2 = df_co2.dropna().set_index(\"Year\")\n",
    "df_temp = df_temp.dropna().set_index(\"Year\")\n",
    "\n",
    "df_merged = df_co2.join(df_temp, how=\"inner\")\n",
    "df_merged = df_merged[df_merged.index >= 1880]\n",
    "\n",
    "expect_rows_between(df_merged, 120, 200, df_name=\"merged climate data\")\n",
    "numeric_sanity_check(df_merged[\"CO2\"], minimum=0, maximum=40, name=\"COâ‚‚ (Gt)\")\n",
    "numeric_sanity_check(df_merged[\"TempAnomaly\"], minimum=-1.0, maximum=1.5, name=\"Temperature anomaly (Â°C)\")\n",
    "quick_null_check(df_merged, df_name=\"merged climate data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_preview(df_merged.head(), n=5, df_name=\"merged climate data\")\n",
    "quick_preview(df_merged.tail(), n=5, df_name=\"recent climate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1579d",
   "metadata": {},
   "source": [
    "## Loop 3 Â· Engineer Evidence Metrics\n",
    "Quantify change for your claim-evidence statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc45e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_year = 1960\n",
    "start_year = df_merged.index.min()\n",
    "latest_year = int(df_merged.index.max())\n",
    "\n",
    "def safe_value(year: int, series: pd.Series) -> float:\n",
    "    if year in series.index:\n",
    "        return float(series.loc[year])\n",
    "    return float(series.loc[series.index[series.index.searchsorted(year)]])\n",
    "\n",
    "co2_baseline = safe_value(baseline_year, df_merged[\"CO2\"])\n",
    "co2_latest = float(df_merged[\"CO2\"].iloc[-1])\n",
    "temp_baseline = safe_value(baseline_year, df_merged[\"TempAnomaly\"])\n",
    "temp_latest = float(df_merged[\"TempAnomaly\"].iloc[-1])\n",
    "corr = df_merged[\"CO2\"].corr(df_merged[\"TempAnomaly\"])\n",
    "\n",
    "print(\n",
    "    f\"Since {baseline_year}, COâ‚‚ rose from {co2_baseline:.1f} Gt to {co2_latest:.1f} Gt.\"                     f\" Temperature anomaly increased from {temp_baseline:.2f}Â°C to {temp_latest:.2f}Â°C.\"\n",
    ")\n",
    "print(f\"Pearson correlation between series: {corr:.2f}\")\n",
    "\n",
    "story = {\n",
    "    \"title\": \"COâ‚‚ Emissions and Global Temperatures Rise in Lockstep\",\n",
    "    \"subtitle\": f\"Global totals, {start_year}â€“{latest_year}\",\n",
    "    \"claim\": \"Burning fossil fuels drives a steep climb in atmospheric COâ‚‚ and global temperature anomalies.\",\n",
    "    \"evidence\": (\n",
    "        f\"COâ‚‚ emissions quadrupled after {baseline_year}, and temperature anomalies climbed ~{temp_latest - temp_baseline:.1f}Â°C.\"                         f\" Correlation = {corr:.2f}.\"\n",
    "    ),\n",
    "    \"visual\": \"Two-panel line chart sharing a timeline (top: COâ‚‚, bottom: temperature anomaly).\",\n",
    "    \"takeaway\": \"Cutting emissions is essential to stabilise temperatures within agreed climate targets.\",\n",
    "    \"source\": \"Global Carbon Project & NASA GISTEMP (2024 release)\",\n",
    "    \"units\": \"COâ‚‚ in gigatonnes; temperature anomaly in Â°C relative to 1951â€“1980\",\n",
    "    \"annotation\": f\"{latest_year}: {co2_latest:.1f} Gt COâ‚‚ and {temp_latest:.2f}Â°C anomaly\",\n",
    "    \"alt_text\": (\n",
    "        \"Two aligned line charts from the late 1800s to present showing COâ‚‚ emissions climbing from under 5 Gt\"\n",
    "        f\" to over {co2_latest:.0f} Gt while temperature anomalies rise from near 0Â°C to about {temp_latest:.1f}Â°C.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "print_story_scaffold(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e40ae",
   "metadata": {},
   "source": [
    "## Loop 4 Â· Compose the Capstone Figure\n",
    "Use a shared timeline, consistent storytelling scaffold, and explicit accessibility log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(12, 9),\n",
    "    sharex=True,\n",
    "    gridspec_kw={\"height_ratios\": [2, 1.2], \"hspace\": 0.05},\n",
    ")\n",
    "\n",
    "ax_co2, ax_temp = axes\n",
    "ax_co2.plot(df_merged.index, df_merged[\"CO2\"], color=\"#6a4c93\", linewidth=3)\n",
    "ax_co2.set_ylabel(\"COâ‚‚ emissions (Gt)\")\n",
    "ax_co2.axvspan(1950, latest_year, color=\"#f6bd60\", alpha=0.15, label=\"Great Acceleration\")\n",
    "ax_co2.legend(loc=\"upper left\")\n",
    "\n",
    "ax_temp.plot(df_merged.index, df_merged[\"TempAnomaly\"], color=\"#ef476f\", linewidth=2.5)\n",
    "ax_temp.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax_temp.set_ylabel(\"Temp anomaly (Â°C)\")\n",
    "ax_temp.set_xlabel(\"Year\")\n",
    "\n",
    "apply_matplotlib_story(ax_co2, story)\n",
    "annotate_callout(\n",
    "    ax_co2,\n",
    "    xy=(latest_year, co2_latest),\n",
    "    xytext=(1985, co2_latest - 10),\n",
    "    text=story[\"annotation\"],\n",
    ")\n",
    "annotate_callout(\n",
    "    ax_temp,\n",
    "    xy=(latest_year, temp_latest),\n",
    "    xytext=(1940, temp_latest + 0.2),\n",
    "    text=f\"{latest_year}: {temp_latest:.2f}Â°C anomaly\",\n",
    ")\n",
    "\n",
    "record_alt_text(story[\"alt_text\"])\n",
    "accessibility_checklist(\n",
    "    palette=\"Purple/rose contrast with shared timeline\",\n",
    "    has_alt_text=True,\n",
    ")\n",
    "\n",
    "fig.align_ylabels(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cbc1f",
   "metadata": {},
   "source": [
    "### ðŸ§¾ Reflection Prompt\n",
    "- Where might the causal chain break? What other evidence would you gather?\n",
    "- How could you adapt this chart for a policymaker vs. a public audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd373b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure(fig, \"day05_solution_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrPwOkZwNEizIssfpEdkJP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
